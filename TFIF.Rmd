---
title: "DESARROLLO DE CLASIFICADOR PARA PACIENTES SOMETIDOS A CIRUGÍA CARDÍACA CON CIRCULACIÓN EXTRACORPÓREA"
author: |
  Autor: Carlos Alejandro Lugones  
  Tutor: Prof. Dr. Rodrigo Ramele
output: 
  html_document:
    self_contained: false  
    embed_resources: true 
    css: styles.css
  word_document: default
  pdf_document: default
---


```{r include=FALSE}
# Código de configuración inicial
knitr::opts_chunk$set(root.dir = "/Users/lugo/Desktop/TFI")
```

```{r include=FALSE}

library(dplyr)
library(PerformanceAnalytics)
library(openxlsx)
library(arsenal)
library(ggplot2)
library(GGally)
library(gridExtra)
library(flextable)
library(MASS)
library(nnet)
library(NeuralNetTools)
library(caret)
library(Hmisc)
library(knitr)
library(RColorBrewer)
library(scales)
library(car)
library(rgl)
library(pROC)
```

# LECTURA DE BASE DE DATOS

```{r include=FALSE}
# Lectura del archivo
data <- read.xlsx("data.xlsx", sheet = 1)
datos <- data
```

```{r echo=FALSE}
# Verificación de estructura
str(datos)
```

```{r echo=FALSE}
# Muestra las primeras filas del data frame
head(datos)

# Reemplazar NA por "NC" en las variables VALVULA y POSICION
datos$VALVULA[is.na(datos$VALVULA)] <- "NC"
datos$POSICION[is.na(datos$POSICION)] <- "NC"

# Verificar los cambios
table(datos$VALVULA)
table(datos$POSICION)

# Reemplazar NA por 0 en las variables BYPASS, BYPASS.ARTERIALES, BYPASS.VENOSOS
datos$BYPASS[is.na(datos$BYPASS)] <- 0
datos$BYPASS.ARTERIALES[is.na(datos$BYPASS.ARTERIALES)] <- 0
datos$BYPASS.VENOSOS[is.na(datos$BYPASS.VENOSOS)] <- 0

# Verificar los cambios
table(datos$BYPASS)
table(datos$BYPASS.ARTERIALES)
table(datos$BYPASS.VENOSOS)

# Transformar BCIAO usando mutate
datos <- datos %>%
  mutate(BCIAO = ifelse(BCIAO == 0, "SIN BCIAO", "CON BCIAO"))

table(datos$BCIAO)

# Conteo del número de filas de la base de datos
nrow(datos)

```

# TRANSFORMACIÓN DE VARIABLES

```{r echo=FALSE}
# transformo la variable BCIA como factor 
datos <- datos %>%
  mutate(across(c(SEX,CIRUGIA,VALVULA, POSICION, HIPOT,BCIAO), as.factor))

# Transformar las variables BYPASS, BYPASS.ARTERIALES, BYPASS.VENOSOS en factores
datos <- datos %>%
  mutate(across(c(BYPASS, BYPASS.ARTERIALES, BYPASS.VENOSOS), as.factor))

# Verificar que las variables se transformaron correctamente
str(datos)
```

```{r echo=FALSE}
# Ver los niveles de varias variables a la vez
niveles <- lapply(datos[c("SEX", "CIRUGIA", "BYPASS", "BYPASS.ARTERIALES", 
                          "BYPASS.VENOSOS", "VALVULA", "POSICION", "HIPOT", "BCIAO")], levels)

# Crear un data frame con las variables y sus niveles en formato de texto
niveles_df <- data.frame(Niveles = sapply(niveles, function(x) paste(x, collapse = ", ")))

# Mostrar la tabla usando kable()
knitr::kable(niveles_df)
```

# CREACION DE VARIABLES

```{r echo=FALSE}
# creo la variable DIFF que determina la complejidad para salir de bomba
datos$DIFF <- datos$T.BOMB - datos$T.CLAMP
summary(datos$DIFF)
```

# ANALISIS EXPLORATORIO

## ANALISIS UNIVARIADO

```{r echo=FALSE}
colnames(datos)
```

### Variable SEXO

```{r echo=FALSE}
# Agrupar por la variable SEX y contar las observaciones en cada grupo
datos %>%
  group_by(SEX) %>%
  summarise(count = n()) %>%
  mutate(percentage = (count / sum(count)) * 100) %>%
  arrange(count) %>%
  head(10)


# Gráfico de barras para la variable SEX
ggplot(datos, aes(x = SEX, fill = SEX)) +
  geom_bar(width = 0.5) +  # Reducción del ancho de las barras al 70%
  scale_fill_manual(values = c("F" = "#fb9a99",  # Rosado suave para F
                               "M" = "#a6cee3")) +  # Azul suave para M
  labs(title = "Distribución de la variable SEX", x = "Sexo", y = "Frecuencia") +  
  theme_minimal() +  
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),  
    axis.title.x = element_text(face = "bold"),  
    axis.title.y = element_text(face = "bold"),  
    legend.position = "none")
```

### Variable CIRUGIA

```{r echo=FALSE}
# Agrupar por la variable CIRUGIA y contar las observaciones en cada grupo
datos %>%
  group_by(CIRUGIA) %>%
  summarise(count = n()) %>%
  mutate(percentage = (count / sum(count)) * 100) %>%
  arrange(count) %>%
  print(n = 30)


# Gráfico de barras para la variable CIRUGIA 

# paleta de colores personalizada 
colores_personalizados <- c("#66c2a5", "#fc8d62", "#8da0cb", "#e78ac3", "#a6d854", 
                                     "#ffd92f", "#e5c494", "#b3b3b3", "#1b9e77", "#d95f02")
                                     
# Gráfico 
ggplot(datos, aes(x = CIRUGIA, fill = CIRUGIA)) +
  geom_bar() +  
  geom_text(aes(label = scales::percent(..count../sum(..count..), accuracy = 0.1)), 
            stat = "count", vjust = -0.5) +  
  scale_fill_manual(values = colores_personalizados) +  
  scale_y_continuous(breaks = seq(0, max(table(datos$CIRUGIA)), by = 50)) +  
  labs(title = "Distribución de la variable CIRUGIA", x = "Cirugía", y = "Frecuencia") +  
  theme_minimal() + 
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),  
    axis.title.x = element_text(face = "bold"), 
    axis.title.y = element_text(face = "bold"),  
    axis.text.x = element_text(angle = 45, hjust = 1),  
    legend.position = "none")

```

### Variable POSICION

Agrupar por la variable POSICION y contar las observaciones en cada grupo tener en cuenta que no todas las cirugías llevan válvula por ende tampoco posición de las mismas es por ello que se filtra los NC en el conteo y porcentajes. Además de no incluirse en los gráficos

```{r echo=FALSE}
datos %>%
  filter(POSICION != "NC") %>%  
  group_by(POSICION) %>%
  summarise(count = n(), .groups = "drop") %>%
  mutate(percentage = (count / sum(count)) * 100) %>%
  arrange(count) %>%
  print(n = 30)

# Filtrar y procesar los datos
datos %>%
  filter(POSICION != "NC") %>%  
  group_by(POSICION) %>%
  summarise(count = n(), .groups = "drop") %>%  
  mutate(percentage = (count / sum(count)) * 100) %>%  
  arrange(count) %>%
  ggplot(aes(x = reorder(POSICION, count), y = count, fill = POSICION)) + 
  geom_bar(stat = "identity") +  
  geom_text(aes(label = sprintf("%.1f%%", percentage)), vjust = -0.5, color = "black") +  
  scale_fill_brewer(palette = "Set3") +  
  labs(
    title = "Distribución de la variable POSICION",
    x = "Posición",
    y = "Frecuencia",
    fill = "Posición"
  ) +  
  theme_minimal() +  
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"), 
    axis.title.x = element_text(face = "bold"), 
    axis.title.y = element_text(face = "bold"),  
    axis.text.x = element_text(angle = 45, hjust = 1), 
    legend.position = "none"  
    )

```

### Variable HPOTERMIA

```{r echo=FALSE}
# Agrupar por la variable HIPOT y contar las observaciones en cada grupo
datos %>%
  group_by(HIPOT) %>%
  summarise(count = n()) %>%
  mutate(percentage = (count / sum(count)) * 100) %>%
  arrange(count) %>%
  print(n = 10)

# gráfico 
datos %>%
  group_by(HIPOT) %>%  
  summarise(count = n(), .groups = "drop") %>%  
  mutate(percentage = (count / sum(count)) * 100) %>%  
  arrange(count) %>%
  ggplot(aes(x = reorder(HIPOT, count), y = count, fill = HIPOT)) +  
  geom_bar(stat = "identity") + 
  geom_text(aes(label = sprintf("%.1f%%", percentage)), vjust = -0.5, color = "black") +  
  scale_fill_brewer(palette = "Set3") +  
  labs(
    title = "Distribución de la variable HIPOT",
    x = "HIPOT",
    y = "Frecuencia",
    fill = "HIPOT"
  ) +  
  theme_minimal() +  
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"), 
    axis.title.x = element_text(face = "bold"),  
    axis.title.y = element_text(face = "bold"), 
    axis.text.x = element_text(angle = 45, hjust = 1), 
    legend.position = "none"  
  )
```

### Variable VÁLVULA

```{r echo=FALSE}
# Agrupar por la variable VALVULA y contar las observaciones en cada grupo
datos %>%
  filter(VALVULA != "NC") %>%  # saco las filas donde VALVULA es NA
  group_by(VALVULA) %>%
  summarise(count = n(), .groups = "drop") %>%
  mutate(percentage = (count / sum(count)) * 100) %>%
  arrange(count) %>%
  print(n = 30)

# gráfico 
datos %>%
  filter(VALVULA != "NC") %>%  # sacolas filas donde VALVULA es NA
  group_by(VALVULA) %>%
  summarise(count = n(), .groups = "drop") %>%  # agrupo por VALVULA
  mutate(percentage = (count / sum(count)) * 100) %>%  # calculo porcentaje
  arrange(count) %>%
  ggplot(aes(x = reorder(VALVULA, count), y = count, fill = VALVULA)) + 
  geom_bar(stat = "identity") +  
  geom_text(aes(label = sprintf("%.1f%%", percentage)), vjust = -0.5, color = "black") +  
  scale_fill_brewer(palette = "Set3") +  
  labs(
    title = "Distribución de la variable VALVULA",
    x = "válvula",
    y = "Frecuencia",
    fill = "válvula"
  ) +  
  theme_minimal() + 
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"), 
    axis.title.x = element_text(face = "bold"),  
    axis.title.y = element_text(face = "bold"), 
    axis.text.x = element_text(angle = 45, hjust = 1), 
    legend.position = "none" 
  )

```

### Variable BCIAO

```{r  echo=FALSE}
# Agrupar por la variable BCIAO y contar las observaciones en cada grupo
datos %>%
  filter(BCIAO != "NC") %>%  # saco las filas donde VALVULA es NA
  group_by(BCIAO) %>%
  summarise(count = n(), .groups = "drop") %>%
  mutate(percentage = (count / sum(count)) * 100) %>%
  arrange(count) %>%
  print(n = 30)

# gráfico
datos %>%
  filter(BCIAO != "NC") %>%  # Excluir las filas donde BCIAO es NC
  group_by(BCIAO) %>%  # Agrupar por BCIAO
  summarise(count = n(), .groups = "drop") %>%  # Calcular la frecuencia
  mutate(percentage = (count / sum(count)) * 100) %>%  # Calcular el porcentaje
  arrange(count) %>%
  ggplot(aes(x = reorder(BCIAO, count), y = count, fill = BCIAO)) +  # Reordenar para el gráfico
  geom_bar(stat = "identity") +  # Crear las barras
  geom_text(aes(label = sprintf("%.1f%%", percentage)), vjust = -0.5, color = "black") +  # Agregar etiquetas de porcentaje
  scale_fill_brewer(palette = "Set3") +  # Paleta de colores atractiva
  labs(
    title = "Distribución de la variable BCIAO",
    x = "BCIAO",
    y = "Frecuencia",
    fill = "BCIAO"
  ) +  # Títulos y etiquetas
  theme_minimal() +  # Tema limpio
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),  # Centrar y negrita el título
    axis.title.x = element_text(face = "bold"),  # Negrita en el eje X
    axis.title.y = element_text(face = "bold"),  # Negrita en el eje Y
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotar etiquetas del eje X
    legend.position = "none"  # Opcional: eliminar leyenda si no es necesaria
  )
```

### Gráfico resumen variables CUALITATIVAS

```{r echo=FALSE, fig.align='center', fig.width= 18, fig.height= 10}
# Seleccionar las columnas cualitativas
qualitative_columns <- c("SEX", "CIRUGIA", "POSICION", "HIPOT", "VALVULA", "BCIAO")
selected_datos <- datos[, qualitative_columns]

# Crear una lista para almacenar los gráficos de barras
barplot_list <- list()

# Crear una paleta de colores que se ajuste dinámicamente al número de categorías
set3_colors <- colorRampPalette(brewer.pal(n = 12, name = "Set3"))(length(unique(unlist(lapply(selected_datos, unique)))))

# Iterar sobre cada columna cualitativa y crear un gráfico de barras
for (i in seq_along(qualitative_columns)) {
  col <- qualitative_columns[i]
  
  # Filtrar los valores "NC" sin eliminarlos del conjunto original
  filtered_col_data <- selected_datos %>% filter(!!sym(col) != "NC")
  
  # Calcular las proporciones de cada categoría
  count_data <- filtered_col_data %>%
    count(!!sym(col)) %>%
    mutate(percentage = n / sum(n) * 100)
  
  # Crear el gráfico de barras con los porcentajes
  p <- ggplot(count_data, aes(x = !!sym(col), y = n, fill = !!sym(col))) +
    geom_bar(stat = "identity", color = "white") +
    scale_fill_manual(values = set3_colors, guide = "none") +  # Eliminar la leyenda
    geom_text(aes(label = paste0(round(percentage, 1), "%")), vjust = -0.5) +  # Añadir los porcentajes
    labs(title = paste("Distribución de", col),
         x = NULL,  # Quitar el nombre de la variable del eje x
         y = "Frecuencia") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotar las etiquetas en el eje x (categorías)
  
  # Agregar el gráfico a la lista
  barplot_list[[col]] <- p
}

# Mostrar los gráficos de barras en una cuadrícula de 3 columnas
grid.arrange(grobs = barplot_list, ncol = 3)

# Restaurar el diseño gráfico predeterminado
par(mfrow = c(1, 1))
```

### Gráfico resumen variables CUANTITATIVAS

```{r echo=FALSE, fig.align='center', fig.width= 10, fig.height= 10}
# Seleccionar las columnas cuantitativas
quantitative_columns <- c("EDAD", "FEY", "T.CLAMP", "T.BOMB" , "DIFF")
selected_datos <- datos[, quantitative_columns]

# Crear una lista para almacenar los gráficos
hist_list <- list()

# Obtener los colores de la paleta "Set3"
set3_colors <- brewer.pal(n = length(quantitative_columns), name = "Set3")

# Iterar sobre cada columna cuantitativa y crear un histograma
for (i in seq_along(quantitative_columns)) {
  col <- quantitative_columns[i]
  
  # Crear el histograma con ggplot2
  p <- ggplot(selected_datos, aes(x = !!sym(col))) +
    geom_histogram(binwidth = 5, fill = set3_colors[i], color = "white") +
    labs(title = paste("Distribución de", col),
         x = "Valores", y = "Frecuencia") +
    theme_minimal()
  
  # Realizar el test de Shapiro-Wilk para normalidad
  shapiro_test <- shapiro.test(selected_datos[[col]])
  
  # Extraer el valor p con solo 2 decimales
  p_value <- format(shapiro_test$p.value, digits = 2)
  
  # Agregar el p-value al gráfico como texto
  p <- p + annotate("text", x = Inf, y = Inf, 
                    label = paste("p value =", p_value), 
                    hjust = 1, vjust = 1, size = 4)
  
  # Agregar el gráfico a la lista
  hist_list[[col]] <- p
}

# Mostrar los histogramas en una cuadrícula
grid.arrange(grobs = hist_list, ncol = 3)

# Restaurar el diseño gráfico predeterminado
par(mfrow = c(1, 1))
```

### Medidas NO PARAMETRICAS de variables cuantitativas

Dado que las variables cuantitativas no presentan distribucion normal se muestra mediana, 1º y 3º quartil, máximos y mínimos

```{r echo=FALSE}
custom_summary <- function(df) {
  summary_stats <- data.frame(
    Min = apply(df, 2, min, na.rm = TRUE),
    `1st Qu.` = apply(df, 2, function(x) quantile(x, 0.25, na.rm = TRUE)),
    Median = apply(df, 2, median, na.rm = TRUE),
    `3rd Qu.` = apply(df, 2, function(x) quantile(x, 0.75, na.rm = TRUE)),
    Max = apply(df, 2, max, na.rm = TRUE)
  )
  return(summary_stats)
}

# Aplicar la función a los datos
P<-custom_summary(selected_datos)
P

# Convertir la tabla a un objeto flextable para exportar a Word
tabla_flex <- regulartable(P)

# Guardar la tabla en un archivo de Word
save_as_docx(tabla_flex, path = "tabla_resumen.docx")
```

### Gráfico resumen de variables cuantitativas (Boxplots)

```{r echo=FALSE, fig.align='center', fig.width= 13, fig.height= 10}
# Seleccionar las columnas cuantitativas
quantitative_columns <- c("EDAD", "FEY", "T.CLAMP", "T.BOMB", "DIFF")
selected_datos <- datos[, quantitative_columns]

# Crear una lista para almacenar los gráficos
boxplot_list <- list()

# Obtener los colores de la paleta "Set3"
set3_colors <- brewer.pal(n = length(quantitative_columns), name = "Set3")

# Iterar sobre cada columna cuantitativa y crear un boxplot
for (i in seq_along(quantitative_columns)) {
  col <- quantitative_columns[i]
  
  # Crear el boxplot con ggplot2
  p <- ggplot(selected_datos, aes(x = "", y = !!sym(col), fill = col)) +
    geom_boxplot(fill = set3_colors[i], color = "blue") +
    labs(title = paste("Boxplot de", col),
         x = "Variable", y = "Valores") +
    theme_minimal()
  
  # Realizar el test de Shapiro-Wilk para normalidad
  shapiro_test <- shapiro.test(selected_datos[[col]])
  
  # Extraer el valor p con solo 2 decimales
  p_value <- format(shapiro_test$p.value, digits = 2)
  
  # Agregar el p-value al gráfico como texto
  p <- p + annotate("text", x = 1, y = max(selected_datos[[col]], na.rm = TRUE), 
                    label = paste("p value =", p_value), 
                    hjust = 2, vjust = 1, size = 3, color = "black")
  
  # Agregar el gráfico a la lista
  boxplot_list[[col]] <- p
}

# Mostrar los boxplots en una cuadrícula
grid.arrange(grobs = boxplot_list, ncol = 3)

# Restaurar el diseño gráfico predeterminado
par(mfrow = c(1, 1))
```

### Identificación de outliers

```{r echo=FALSE}
# Función para detectar outliers usando el rango intercuartílico (IQR)
detectar_outliers <- function(data, columna) {
  Q1 <- quantile(data[[columna]], 0.25, na.rm = TRUE)
  Q3 <- quantile(data[[columna]], 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  limite_inferior <- Q1 - 1.5 * IQR
  limite_superior <- Q3 + 1.5 * IQR
  # Detectamos los outliers que están fuera de los límites
  outliers <- data[data[[columna]] < limite_inferior | data[[columna]] > limite_superior, ]
  outliers$Variable <- columna
  return(outliers)
}

# Variables cuantitativas que queremos analizar
variables_cuantitativas <- c("EDAD", "T.CLAMP", "T.BOMB", "DIFF")

# Crear un nuevo dataframe vacío para almacenar los outliers
df_outliers <- data.frame()

# Extraer los outliers para cada variable y combinarlos, manteniendo el orden por variable
for (variable in variables_cuantitativas) {
  outliers_variable <- detectar_outliers(datos, variable)
  df_outliers <- rbind(df_outliers, outliers_variable)
}

# Ordenar el dataframe por la columna 'Variable'
df_outliers <- df_outliers[order(df_outliers$Variable), ]

# Reordenar columnas para que 'Variable' sea la primera
df_outliers <- df_outliers[, c("Variable", setdiff(names(df_outliers), "Variable"))]

# Mostrar cuantos outliers hay en el dataframe y ordenarlos
nrow(df_outliers)

# Mostrar llas primeras rows del dataframe 
head (df_outliers)
tail(df_outliers)

# Contar el número de outliers por variable
outliers_por_variable <- sapply(variables_cuantitativas, function(variable) {
  nrow(detectar_outliers(datos, variable))
})

# Crear un dataframe con la variable y la cantidad de outliers
df_outliers_count <- data.frame(
  Variable = names(outliers_por_variable),
  Cantidad_Outliers = outliers_por_variable
)

# Mostrar la tabla 
print(df_outliers_count)

```

## ANALISIS BIVARIADO

### DIFF según BCIAO

```{r echo=FALSE}

# Gráfico
ggplot(datos, aes(x = BCIAO, y = DIFF, fill = BCIAO)) +
  geom_boxplot(alpha = 0.7) + 
  labs(title = "Comparación de DIFF según BCIAO",
       x = "BCIAO", 
       y = "DIFF") +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_fill_brewer(palette = "Set3")  

# Test de Wilcoxon-Mann-Whitney
wilcox_test <- wilcox.test(DIFF ~ BCIAO, data = datos, conf.int= 0.95)

# Ver los resultados del test
print(wilcox_test)
```

### FEY según BCIAO 

```{r echo=FALSE}

ggplot(datos, aes(x = BCIAO, y = FEY, fill = BCIAO)) +
  geom_boxplot(alpha = 0.7) + 
  labs(title = "Comparación de FEY según BCIAO",
       x = "BCIAO", 
       y = "FEY") +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_fill_brewer(palette = "Set3")  # Mejora la estética de los colores

# Test de Wilcoxon-Mann-Whitney
wilcox_test <- wilcox.test(FEY ~ BCIAO, data = datos, conf.int= 0.95)

# Ver los resultados del test
print(wilcox_test)
```

Intervalo de Confianza: El intervalo de confianza del 95% para la diferencia de medianas es de [-14.00004, -12.00001]. Esto indica que, con un 95% de confianza, la diferencia en la mediana de FEY entre los grupos se encuentra en este rango. Como ambos límites son negativos, esto sugiere que FEY es menor en el grupo con BCIAO = 1 que en el grupo con BCIAO = 0.

Estimación de la Diferencia de Localización: La diferencia en la ubicación (o mediana) entre los grupos es de -13.0000
lo que respalda que el grupo con BCIAO = 1 tiene una mediana de FEY aproximadamente 13 unidades menor que el grupo con BCIAO = 0.

### BCIAO según SEX

```{r echo=FALSE}

# Gráfico de barras apilado
ggplot(datos, aes(x = SEX, fill = BCIAO)) +
  geom_bar(position = "fill") +
  labs(title = "Distribución de BCIAO según SEX",
       x = "Sexo", 
       y = "Proporción") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3")

# Tabla de contingencia entre SEX y BCIAO
tabla_sex_bciao <- table(datos$SEX, datos$BCIAO)
tabla_sex_bciao

# verifico cumplimiento de los supuestos para Chi cuadrado
supuesto<- chisq.test(tabla_sex_bciao)
supuesto$expected

# Resultado de la prueba
chisq_test_sex <- chisq.test(tabla_sex_bciao)
print(chisq_test_sex)
```

### BCIAO según CIRUGIA

```{r echo=FALSE, fig.align='center', fig.width=10, fig.height=7}

# Gráfico de barras apilado
ggplot(datos, aes(x = CIRUGIA, fill = BCIAO)) +
  geom_bar(position = "fill") +
  labs(title = "Distribución de BCIAO según CIRUGIA",
       x = "cirugía", 
       y = "Proporción") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3")

# tabla de contingencia entre CIRUGIA y BCIAO
tabla_cirugia_bciao <- table(datos$CIRUGIA, datos$BCIAO)
print(tabla_cirugia_bciao)

# Comprobar las frecuencias esperadas
chi_test_cirugia <- chisq.test(tabla_cirugia_bciao)

# Mostrar las frecuencias esperadas
print(chi_test_cirugia$expected)

#El test de Fisher tampoco da por la multiplicidad de categoríase
#Usar simulación de Monte Carlo para calcular el valor p en Fisher 
fisher_test_cirugia_sim <- fisher.test(tabla_cirugia_bciao, simulate.p.value = TRUE, B = 1e5)

# resultado de la prueba con simulación
print(fisher_test_cirugia_sim)
```

### BCIAO según VALVULA

```{r echo=FALSE}

# Filtrar datos donde VALVULA no sea "NC" y eliminar niveles no usados
datos_filtrados <- droplevels(datos[datos$VALVULA != "NC", ])

# Gráfico de barras apilado sin "NC" en VALVULA
ggplot(datos_filtrados, aes(x = VALVULA, fill = BCIAO)) +
  geom_bar(position = "fill") +
  labs(title = "Distribución de BCIAO según VALVULA",
       x = "Tipo de válvula", 
       y = "Proporción") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3")

# Tabla de contingencia entre VALVULA y BCIAO con los datos filtrados
tabla_val_bciao <- table(datos_filtrados$VALVULA, datos_filtrados$BCIAO)
print(tabla_val_bciao)

# Verificar el cumplimiento de los supuestos para Chi-Cuadrado
supuesto <- chisq.test(tabla_val_bciao)
print(supuesto$expected)

# Realizar el test de chi-cuadrado
chisq_test_valvula <- chisq.test(tabla_val_bciao)
print(chisq_test_valvula)
```

### BCIAO según POSICION

```{r echo=FALSE}

# Filtrar datos donde POSICION no sea "NC" y eliminar niveles no usados
datos_filtrados <- droplevels(datos[datos$POSICION != "NC", ])

# Crear el gráfico sin la categoría NA
ggplot(datos_filtrados, aes(x = POSICION, fill = BCIAO)) +
  geom_bar(position = "fill") +
  labs(title = "Distribución de BCIAO según POSICIÓN",
       x = "Posición", 
       y = "Proporción") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3")

# Tabla de contingencia entre VALVULA y BCIAO con los datos filtrados
tabla_pos_bciao <- table(datos_filtrados$POSICION, datos_filtrados$BCIAO)
print(tabla_pos_bciao)

# Verificar el cumplimiento de los supuestos para Chi-Cuadrado
supuesto_pos <- chisq.test(tabla_pos_bciao)
print(supuesto_pos$expected)

# Si las frecuencias esperadas son mayores a 5, se puede usar chi-cuadrado
if (all(supuesto_pos$expected > 5)) {
  chisq_test_pos <- chisq.test(tabla_pos_bciao, correct = T)
  print(chisq_test_pos)
} else {
  # Si alguna frecuencia es menor a 5, se realiza el test de Fisher
  fisher_test_pos <- fisher.test(tabla_pos_bciao)
  print(fisher_test_pos)
}
```

### BCIAO según HIPOTERMIA

```{r echo=FALSE}

# Gráfico de barras apilado para HIPOT y BCIAO
ggplot(datos_filtrados , aes(x = HIPOT, fill = BCIAO)) +
  geom_bar(position = "fill") +
  labs(title = "Distribución de BCIAO según HIPOTERMIA",
       x = "Hipotermia", 
       y = "Proporción") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3")

# Tabla de contingencia entre HIPOT y BCIAO
tabla_hipot_bciao <- table(datos$HIPOT, datos$BCIAO)
print(tabla_hipot_bciao)

# Verificación de los supuestos del test de Chi-cuadrado
supuesto_hipot <- chisq.test(tabla_hipot_bciao)
print(supuesto_hipot$expected) # Frecuencias esperadas

# Si las frecuencias esperadas son mayores a 5, se puede usar chi-cuadrado
if (all(supuesto_hipot$expected > 5)) {
  chisq_test_hipot <- chisq.test(tabla_hipot_bciao)
  print(chisq_test_hipot)
} else {
  # Si alguna frecuencia es menor a 5, se realiza el test de Fisher
  fisher_test_hipot <- fisher.test(tabla_hipot_bciao)
  print(fisher_test_hipot)
}
```

### EDAD según BCIAO

```{r echo=FALSE}

# Gráfico de cajas (boxplot) para visualizar EDAD según BCIAO
ggplot(datos, aes(x = factor(BCIAO), y = EDAD, fill = factor(BCIAO))) +
  geom_boxplot() +
  labs(title = "Distribución de la EDAD según BCIAO",
       x = "BCIAO",
       y = "Edad") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set3") +
  guides(fill = "none") 

# Test de Mann-Whitney para comparar EDAD según BCIAO
mann_whitney_test <- wilcox.test(EDAD ~ BCIAO, data = datos, conf.int= 0.95)

# Mostrar el resultado del test
print(mann_whitney_test)
```

### Correlaciones bivariadas

```{r echo=FALSE, warning=FALSE}

# correlaciones bivariadas con test de Spearman dado que las distribuciones no asumen normalidad 

# EDAD-FEY
shapiro.test(datos$EDAD)
shapiro.test(datos$FEY)
cor.test(datos$EDAD,datos$FEY, method = "spearman",exact=FALSE)
dat1 <- data.frame(datos$EDAD,datos$FEY)
chart.Correlation(dat1, method = "spearman", exact=F)

#EDAD-DIFF
# Prueba de normalidad para EDAD y DIFF
shapiro.test(datos$EDAD)  
shapiro.test(datos$DIFF)  

# Prueba de correlación de Spearman entre EDAD y DIFF
cor.test(datos$EDAD, datos$DIFF, method = "spearman", exact = FALSE)

# Crear un nuevo data frame con EDAD y DIFF
dat2 <- data.frame( EDAD = datos$EDAD, DIFF = datos$DIFF)

# Gráfico de correlación
chart.Correlation(dat2, method = "spearman", exact = FALSE)

# Crear el modelo LOESS para EDAD y DIFF (análisis de regresión local)
modelo_loess <- loess(DIFF ~ EDAD, data = dat2, span = 0.75)

# Visualizar los valores ajustados
summary(modelo_loess)

# Graficar LOESS para visualizar la relación entre EDAD y DIFF
ggplot(dat2, aes(x = EDAD, y = DIFF)) +
  geom_point(color = "blue", alpha = 0.6) +         # Gráfico de dispersión
  geom_smooth(method = "loess", span = 0.75, color = "red") +  # Ajuste LOESS
  labs(title = "Ajuste LOESS DIFF según EDAD",
       x = "EDAD",
       y = "DIFF") +
  theme_minimal()


#FEY-DIFF
shapiro.test(datos$FEY)
shapiro.test(datos$DIFF)
cor.test(datos$FEY,datos$DIFF, method = "spearman",exact=FALSE)
dat3 <- data.frame(FEY = datos$FEY, DIFF = datos$DIFF)
chart.Correlation(dat3, method = "spearman", exact=F)

# Crear el modelo LOESS para FEY y DIFF
modelo_loess <- loess(DIFF ~ FEY, data = dat3, span = 0.75) 

# Visualizar los valores ajustados
summary(modelo_loess)

# Graficar LOESS para visualizar la relación entre FEY y DIFF
ggplot(dat3, aes(x = FEY, y = DIFF)) +
  geom_point(color = "blue", alpha = 0.6) +         # Gráfico de dispersión
  geom_smooth(method = "loess", span = 0.75, color = "red") +  # Ajuste LOESS
  labs(title = "Ajuste LOESS DIFF según FEY",
       x = "FEY",
       y = "DIFF") +
  theme_minimal()
```


```{r echo=FALSE}

# Selecciona las columnas específicas
datos_cuanti <- datos[c("EDAD","FEY","T.BOMB","T.CLAMP","DIFF")]
# Obtener el resumen estadístico
summary <- summary(datos_cuanti)
# Mostrar el resumen
print(summary)
```


```{r echo=FALSE, warning=FALSE, fig.align='center', fig.width=10, fig.height=10}
ggpairs(datos[c("EDAD", "FEY", "T.BOMB", "T.CLAMP", "DIFF")], 
        aes(color = datos$SEX, alpha = 0.5),
        upper = list(continuous = wrap(ggally_cor, method = "spearman", size = 4)),
        lower = list(continuous = wrap("smooth", alpha = 0.3)),
        diag = list(continuous = "densityDiag")) 
```

### DIFF según SEXO

```{r echo=FALSE}

# Crear el gráfico de caja diferenciando colores por grupo de SEX
boxplot <- ggplot(datos, aes(x = factor(SEX), y = DIFF, fill = factor(SEX))) +
  geom_boxplot(color = "blue") +  
  scale_fill_manual(values = c("#66c2a5", "#fc8d62")) +  
  labs(title = "Box Plot de DIFF según SEXO",
       x = "SEX", y = "DIFF") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    legend.position = "none"  # Ocultar la leyenda
  )

# Mostrar el gráfico
print(boxplot)

# Seleccionar las columnas 'SEX' y 'DIFF'
dfSEX <- datos %>% dplyr::select(SEX, DIFF)

# Calcular las medias agrupadas por 'SEX'
meansSEX <- dfSEX %>% 
  group_by(SEX) %>% 
  summarise(mean_DIFF = mean(DIFF))

# Presentar el resultado como un cuadro
knitr::kable(meansSEX, caption = "Tabla de medias de DIFF por SEX")

# test de levene 
leveneTest(DIFF ~ SEX, data = datos)

# Realizar el análisis ANOVA de Welch ya que no se cumple el supuesto de homocedasticidad (igualdad de varianzas)
oneway.test(DIFF ~ SEX, data = datos, var.equal = FALSE)

# pruebo con wilcoxon asumiento que la distribucion de la varibale DIFF no es normal 
wilcox.test(DIFF ~ SEX, data = datos)

# en ambos casos puedo decir que no hay diferencias significativas en (media/mediana) de la DIFF entre 
# H y M 
```

### DIFF según CIRUGIA

```{r echo=FALSE, warning=FALSE, fig.align='center', fig.width=10, fig.height=7}

# Definir una paleta de colores personalizada
colores_personalizados <- c("#66c2a5", "#fc8d62", "#8da0cb", "#e78ac3", "#a6d854", 
                            "#ffd92f", "#e5c494", "#b3b3b3", "#1b9e77", "#d95f02")

# Crear el gráfico de caja utilizando la paleta personalizada
boxplot <- ggplot(data = as.data.frame(datos), aes(x = factor(CIRUGIA), y = DIFF, fill = factor(CIRUGIA))) +
  geom_boxplot(color = "black") +  # Bordes en negro
  scale_fill_manual(values = colores_personalizados) +  # Aplicar la paleta personalizada
  labs(title = "Box Plot de DIFF según CIRUGIA",
       x = "CIRUGIA", y = "DIFF") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    legend.position = "none"  # Ocultar la leyenda
  )

print(boxplot)

# Calcular las medias de DIFF por CIRUGIA
meansCIRUGIA <- aggregate(DIFF ~ CIRUGIA, data = datos, FUN = mean)

# Ordenar por mean_DIFF
meansCIRUGIA <- meansCIRUGIA[order(meansCIRUGIA$DIFF), ]

# Presentar los resultados como un cuadro
kable(meansCIRUGIA, caption = "Tabla de medias de DIFF por CIRUGIA")

# test de levene 
leveneTest(DIFF ~ CIRUGIA, data = datos)

# Realizar el análisis ANOVA de Welch ya que no se cumple el supuesto de homocedasticidad (igualdad de varianzas)
oneway.test(DIFF ~ CIRUGIA, data = datos, var.equal = FALSE)

# Realizar la prueba t de pares asegurando que todos los grupos estén presentes
resultados_test <- pairwise.t.test(datos$DIFF, datos$CIRUGIA, p.adjust.method = "bonferroni", pool.sd = FALSE)

# Convertir los resultados a un data frame
resultados_df <- as.data.frame(resultados_test$p.value)

# Mostrar la tabla con kable
kable(resultados_df, caption = "Resultados del Test de Comparación Múltiple (Bonferroni)")

```
### DIFF según VALVULA 

```{r echo=FALSE}
# Filtrar datos donde VALVULA no sea "NC" y eliminar niveles no usados
datos_filtrados <- droplevels(datos[datos$VALVULA != "NC", ])

# Asegúrate de que hay suficientes colores para todos los niveles de VALVULA
# Aquí he añadido un tercer color, pero puedes agregar más si es necesario

# Crear el gráfico de caja diferenciando colores por grupo de VALVULA
boxplot <- ggplot(datos_filtrados, aes(x = factor(VALVULA), y = DIFF, fill = factor(VALVULA))) +
  geom_boxplot(color = "blue") + 
  scale_fill_manual(values = c("#66c2a5", "#fc8d62", "#8da0cb")) +  
  labs(title = "Box Plot de DIFF según VALVULA",
       x = "VALVULA", y = "DIFF") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    legend.position = "none"  # Ocultar la leyenda
  )

# Mostrar el gráfico
print(boxplot)

# Seleccionar las columnas 'SEX' y 'DIFF'
dfVAL <- datos_filtrados  %>% dplyr::select(VALVULA, DIFF)

# Calcular las medias agrupadas por 'SEX'
meansVAL <- dfVAL %>% 
  group_by(VALVULA) %>% 
  summarise(mean_DIFF = mean(DIFF))

# Presentar el resultado como un cuadro
knitr::kable(meansVAL, caption = "Tabla de medias de DIFF por VALVULA")

# test de levene 
leveneTest(DIFF ~ VALVULA, data = datos_filtrados )

# Realizar el análisis ANOVA de Welch ya que no se cumple el supuesto de homocedasticidad (igualdad de varianzas)
oneway.test(DIFF ~ VALVULA, data = datos_filtrados , var.equal = FALSE)

# pruebo con wilcoxon asumiento que la distribucion de la varibale DIFF no es normal 
wilcox.test(DIFF ~ VALVULA, data = datos_filtrados )
```

### DIFF según POSICION

```{r echo=FALSE}

# Filtrar datos donde VALVULA no sea "NC" y eliminar niveles no usados
datos_filtrados <- droplevels(datos[datos$POSICION!= "NC", ])

# Crear el gráfico de caja diferenciando colores por grupo de VALVULA
boxplot <- ggplot(datos_filtrados, aes(x = factor(VALVULA), y = DIFF, fill = factor(VALVULA))) +
  geom_boxplot(color = "blue") +  # Bordes en azul sin cambiar el grosor
  scale_fill_manual(values = c("#66c2a5", "#fc8d62")) +  # Colores suficientes para todos los niveles
  labs(title = "Box Plot de DIFF según POSICION",
       x = "VALVULA", y = "DIFF") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    legend.position = "none"  # Ocultar la leyenda
  )

# Mostrar el gráfico
print(boxplot)

# Seleccionar las columnas 'SEX' y 'DIFF'
dfPOSC <- datos_filtrados  %>% dplyr::select(POSICION, DIFF)

# Calcular las medias agrupadas por 'SEX'
meansPOSC <- dfPOSC %>% 
  group_by(POSICION) %>% 
  summarise(mean_DIFF = mean(DIFF))

# Presentar el resultado como un cuadro
knitr::kable(meansPOSC, caption = "Tabla de medias de DIFF por POSICION")

# test de levene 
leveneTest(DIFF ~ POSICION, data = datos_filtrados )

# Realizar el análisis ANOVA de Welch ya que no se cumple el supuesto de homocedasticidad (igualdad de varianzas)
oneway.test(DIFF ~ POSICION, data = datos_filtrados , var.equal = FALSE)

# Realizar la prueba t de pares asegurando que todos los grupos estén presentes
resultados_test <- pairwise.t.test(datos_filtrados$DIFF, datos_filtrados$POSICION, p.adjust.method = "bonferroni", pool.sd = FALSE)

# Convertir los resultados a un data frame
resultados_df <- as.data.frame(resultados_test$p.value)

# Mostrar la tabla con kable
kable(resultados_df, caption = "Resultados del Test de Comparación Múltiple (Bonferroni)")

# KRUSKAL WALLIS
kruskal.test(DIFF ~ POSICION, data = datos_filtrados)
```

### DIFF según HIPOTERMIA

```{r echo=FALSE}
# Crear el gráfico de caja con colores diferenciados según el grupo de HIPOT
boxplot <- ggplot(datos, aes(x = factor(HIPOT), y = DIFF, fill = factor(HIPOT))) +
  geom_boxplot(color = "blue") +  # Bordes en azul sin cambiar el grosor
  scale_fill_manual(values = c("#66c2a5", "#fc8d62")) +  # Aplicar la paleta personalizada
  labs(title = "Box Plot de DIFF según HIPOTERMIA",
       x = "HIPOT", y = "DIFF") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    legend.position = "none"  # Ocultar la leyenda
  )

# Mostrar el gráfico
print(boxplot)

# Seleccionar las columnas 'SEX' y 'DIFF'
dfHIPOT <- datos %>% dplyr::select(HIPOT, DIFF)

# Calcular las medias agrupadas por 'SEX'
meansHIPOT <- dfHIPOT %>% 
  group_by(HIPOT) %>% 
  summarise(mean_DIFF = mean(DIFF))

# Presentar el resultado como un cuadro
knitr::kable(meansHIPOT, caption = "Tabla de medias de DIFF por HIPOT")

# test de levene 
leveneTest(DIFF ~ HIPOT, data = datos)

# Realizar el análisis ANOVA de Welch ya que no se cumple el supuesto de homocedasticidad (igualdad de varianzas)
oneway.test(DIFF ~ HIPOT, data = datos, var.equal = FALSE)

# pruebo con wilcoxon asumiento que la distribucion de la varibale DIFF no es normal 
wilcox.test(DIFF ~ HIPOT, data = datos)
```


### Tablas Resumen variables CUALITATIVAS vs BCIAO

```{r echo=FALSE}

# Crear un subset de 'datos' sin filas con "NC" y eliminar niveles no observados
tabla_filtrada<- datos %>%
  filter(POSICION != "NC", VALVULA != "NC") %>%
  droplevels()

# Generar las tablas usando `tableby`
tabla_cuali1 <- tableby(BCIAO ~ POSICION + VALVULA, data = tabla_filtrada, cat.test = "chisq")

tabla_cuali2 <- tableby(BCIAO ~ chisq (SEX) + chisq (HIPOT) + fe (CIRUGIA), data = datos, simulate.p.value=TRUE, B=1e5)

# Convertir a kable y presentar
kable(summary(tabla_cuali1, text = TRUE))
kable(summary(tabla_cuali2, text = TRUE))
```

### Tablas Resumen variables CUANTITATIVAS vs BCIAO

```{r echo=FALSE}

#### tabla de las variables CUANTI vs BCIAO ####

# Tabla de variables CUANTI vs BCIAO
tabla_cuanti <- tableby(BCIAO ~ EDAD + FEY + T.CLAMP + T.BOMB + DIFF , data = datos, numeric.test = "kwt", numeric.stats = c( "N", "median", "q1q3","range"), stats.labels=list(N='N', median='Mediana', q1q3='Q1,Q3', range="rango"), digits=0)

# Convertir a kable y presentar
kable(summary(tabla_cuanti, text = T))

```

# BALANCEADO DE LABEL

```{r echo=FALSE, include=FALSE}
# Filtrar las filas donde BCIAO es igual a "CON BALON" y obtener el número de filas
con_balon_rows <- which(datos$BCIAO == "CON BCIAO")
n_filas_con_balon <- length(con_balon_rows)

# Mostrar los números de fila y el conteo total
con_balon_rows
n_filas_con_balon

# Filtrar todos los casos con "CON BCIAO"
con_bciao <- subset(datos, BCIAO == "CON BCIAO")

# Filtrar todos los casos con "SIN BCIAO"
sin_bciao <- subset(datos, BCIAO == "SIN BCIAO")

# Seleccionar aleatoriamente 413 filas de los casos "SIN BCIAO"
set.seed(27848992)  # Fijar semilla para reproducibilidad
sin_bciao_sample <- sin_bciao[sample(nrow(sin_bciao), 413), ]

# Combinar ambos subsets para tener un conjunto balanceado
datos1<- rbind(con_bciao, sin_bciao_sample)
```


```{r echo=FALSE}
# Verificar la estructura del subset balanceado
table(datos1$BCIAO)
nrow(datos1)
```

# ____ PREQUIRÚRGICO (BCIAO) ____

# RED NEURONAL

## MODELO PREDICTIVO

```{r echo=FALSE, include=FALSE}

# Particionamiento 70/30 en conjunto de entrenamiento y testeo
set.seed(27848992)
particion <- createDataPartition(y = datos1$BCIAO, p = 0.7, list = FALSE) 
entreno <- datos1[particion, ]
testeo <- datos1[-particion, ]

# Verificar si hay valores NA en los datos de entrenamiento
summary(entreno)
summary(testeo)

# Eliminar NAs y asegurarse de que la variable dependiente es un factor
entreno <- na.omit(entreno)
entreno$BCIAO <- as.factor(entreno$BCIAO)

# Corroboro cantidad de casos en la partición 
dim(entreno)
dim(testeo)

# Corroboro porcentaje en la particion
table(datos1$BCIAO)
table(entreno$BCIAO)
table(testeo$BCIAO)
```

```{r echo=FALSE}
porc_entreno<-(table(entreno$BCIAO)*100)/table(datos1$BCIAO)
porc_entreno

porc_testeo<-(table(testeo$BCIAO)*100)/table(datos1$BCIAO)
porc_testeo
```

## ENTRENAMIENTO DEL MODELO

```{r echo=FALSE, include=FALSE}

# Crear la cuadrícula de hiperparametros (size=neuronas) 
# decay(regularizacion L2 penaliza por pesos grandes para evitar overfitting)
tune_grid <- expand.grid(size = c(1, 3, 5), decay = c(0, 0.01, 0.1, 0.0001))

# Configuración de la validación cruzada de 5-folds
control <- trainControl(method = "cv", number = 5)  # Validación cruzada de 5-folds

# Entrenamiento del modelo de red neuronal con validación cruzada
set.seed(27848992)
red_cv <- train(BCIAO ~ SEX + EDAD + VALVULA + POSICION + FEY + CIRUGIA + HIPOT,
                data = entreno,
                method = "nnet",    # Modelo de red neuronal
                trControl = control, # Validación cruzada
                linout = FALSE,      # Salida no lineal
                maxit = 300,         # Número máximo de iteraciones
                tuneGrid = tune_grid) # Cuadrícula de hiperparámetros
```

```{r echo=FALSE}
# Extrae los pesos sinápticos
pesos <- red_cv$finalModel$wts  
print(pesos)

# Visualizacion del modelo con validación cruzada
print(red_cv) # Resumen del modelo entrenado
```

```{r echo=FALSE}
plot(red_cv) # Gráfico de rendimiento del modelo
```


```{r echo=FALSE, fig.align='center', fig.width= 22, fig.height= 12}
plotnet(red_cv, struct = T, bias = T, circle_cex = 3, cex_val = 0.9, line_stag = 0.02) 
```

## EVALUACIÓN DEL MODELO

```{r echo=FALSE, include=FALSE}

# Predicción y matriz de confusión en el conjunto de testeo con umbral por defecto 0.5
pred_cv <- predict(red_cv, newdata = testeo)

#comparacion real vs predicción
comparacion<- data.frame( real= testeo$BCIAO, prediccion = pred_cv)
comparacion
```

```{r echo=FALSE}
# Matriz de confusión sin curva ROC con umbral 0.5 (default)
matriz_default<-confusionMatrix(factor(pred_cv), factor(testeo$BCIAO))
matriz_default 
```

```{r echo=FALSE}
# Extraer tabla de confusión de la matriz
tabla_confusion<-matriz_default$table
tabla_confusion

# Cálculo de métricas
VP<- tabla_confusion["CON BCIAO", "CON BCIAO"]  # Verdaderos positivos
VN<- tabla_confusion["SIN BCIAO", "SIN BCIAO"]  # Verdaderos negativos
FP<- tabla_confusion["CON BCIAO", "SIN BCIAO"]  # Falsos positivos
FN<- tabla_confusion["SIN BCIAO", "CON BCIAO"]  # Falsos negativos

# Calcular métricas adicionales
sensibilidad <- VP / (VP + FN) 
especificidad <- VN / (VN + FP) 
tasa_acierto <- (VP + VN) / (VP + VN + FP + FN) 
tasa_error <- (FP + FN) / (VP + VN + FP + FN) 
precision <- VP / (VP + FP)

# Cálculo del F1 Score
F1_score <- 2 * (precision * sensibilidad) / (precision + sensibilidad)
F1_score
```


## CURVA ROC Y AUC

```{r echo=FALSE}

# Generar pobabilidades de prediccion
pred_probs <- predict(red_cv, newdata = testeo, type = "prob")[, 1]  # Probabilidad de la clase positiva

# Calculo de curva ROC y AUC
roc_curve <- roc(testeo$BCIAO, pred_probs) 
auc<-auc(roc_curve) 
IC_auc<-ci.auc(roc_curve, conf.level = 0.95) 
auc
IC_auc

# visualizacion de la curva ROC
# Convertir el objeto ROC a un data frame para ggplot2
roc_data <- data.frame(
  Sensitivity = rev(roc_curve$sensitivities),
  Specificity = rev(1 - roc_curve$specificities)
)

# Graficar la curva ROC con ggplot2
ggplot(roc_data, aes(x = Specificity, y = Sensitivity)) +
  geom_line(color = "darkblue", size = 1.2) +                      # Curva ROC
  geom_ribbon(aes(ymin = 0, ymax = Sensitivity), fill = "skyblue", alpha = 0.4) +  # Sombreado de AUC uniforme
  labs(
    title = "Curva ROC",
    x = "1 - Especificidad (Tasa de Falsos Positivos)",
    y = "Sensibilidad (Tasa de Verdaderos Positivos)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 16),  # Título centrado y en negrita
    axis.title = element_text(size = 14),                              # Tamaño de títulos de ejes
    axis.text = element_text(size = 12)                                # Tamaño de etiquetas de ejes
  ) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "gray") +  # Línea de referencia diagonal
  scale_x_continuous(limits = c(0, 1)) +   # Limitar eje x entre 0 y 1
  scale_y_continuous(limits = c(0, 1))     # Limitar eje y entre 0 y 1
```

## DETERMINACION DEL UMBRAL OPTIMO Y MATRIZ OPTIMIZADA

```{r echo=FALSE}

# curva ROC para elegir un umbral óptimo basado en el trade-off entre sensibilidad (recall) y especificidad.
optimal_threshold <- coords(roc_curve, "best", ret = "threshold")$threshold[1]
optimal_threshold

# Umbral óptimo calculado
threshold <- optimal_threshold
threshold

# Predicción con el umbral óptimo (threshold 0.5432122)
pred_cv_class_optimal <- ifelse(pred_probs > threshold, "CON BCIAO", "SIN BCIAO") # Clasificaciones basadas en el umbral
pred_cv_class_optimal <- factor(pred_cv_class_optimal, levels = c("CON BCIAO", "SIN BCIAO")) # Convertir a factor

# Verificar la longitud de las predicciones
length(pred_cv_class_optimal)  # deberia ser 246
```

```{r echo=FALSE}
# Matriz de confusión optima
matriz_optima<-confusionMatrix(pred_cv_class_optimal, factor(testeo$BCIAO))
matriz_optima
```

```{r echo=FALSE, include=FALSE}
# Extraer tabla de confusión de la matriz
tabla_confusion<-matriz_optima$table
tabla_confusion

# Cálculo de métricas
VP<- tabla_confusion["CON BCIAO", "CON BCIAO"]  # Verdaderos positivos
VN<- tabla_confusion["SIN BCIAO", "SIN BCIAO"]  # Verdaderos negativos
FP<- tabla_confusion["CON BCIAO", "SIN BCIAO"]  # Falsos positivos
FN<- tabla_confusion["SIN BCIAO", "CON BCIAO"]  # Falsos negativos

# Calcular métricas adicionales
sensibilidad <- VP / (VP + FN) 
especificidad <- VN / (VN + FP) 
tasa_acierto <- (VP + VN) / (VP + VN + FP + FN) 
tasa_error <- (FP + FN) / (VP + VN + FP + FN) 
precision <- VP / (VP + FP)
```

```{r echo=FALSE}
# Cálculo del F1 Score
F1_score <- 2 * (precision * sensibilidad) / (precision + sensibilidad)
F1_score
```

## ANÁLISIS Y VISUALIZACIÓN DE MÉTRICAS SEGÚN UMBRAL

```{r echo=FALSE, warning=FALSE}

# Predecir probabilidades en el conjunto de testeo
pred_probs <- predict(red_cv, newdata = testeo, type = "prob")[, "CON BCIAO"]  # Asumimos que "CON BCIAO" es la clase positiva

# Crear secuencia de umbrales
thresholds <- seq(0, 1, by = 0.001)

# Calcular métricas en función del umbral
metrics <- data.frame(
  Threshold = thresholds,
  Sensitivity = sapply(thresholds, function(t) { 
    confusionMatrix(factor(ifelse(pred_probs > t, "CON BCIAO", "SIN BCIAO"), 
                           levels = c("CON BCIAO", "SIN BCIAO")),
                    factor(testeo$BCIAO, levels = c("CON BCIAO", "SIN BCIAO")))$byClass["Sensitivity"]
  }),
  Specificity = sapply(thresholds, function(t) { 
    confusionMatrix(factor(ifelse(pred_probs > t, "CON BCIAO", "SIN BCIAO"), 
                           levels = c("CON BCIAO", "SIN BCIAO")),
                    factor(testeo$BCIAO, levels = c("CON BCIAO", "SIN BCIAO")))$byClass["Specificity"]
  }),
  Precision = sapply(thresholds, function(t) { 
    confusionMatrix(factor(ifelse(pred_probs > t, "CON BCIAO", "SIN BCIAO"), 
                           levels = c("CON BCIAO", "SIN BCIAO")),
                    factor(testeo$BCIAO, levels = c("CON BCIAO", "SIN BCIAO")))$byClass["Pos Pred Value"]
  }),
  Tasa_Acierto = sapply(thresholds, function(t) {
    matriz_confusion <- confusionMatrix(factor(ifelse(pred_probs > t, "CON BCIAO", "SIN BCIAO"), 
                                               levels = c("CON BCIAO", "SIN BCIAO")),
                                        factor(testeo$BCIAO, levels = c("CON BCIAO", "SIN BCIAO")))
    VP <- matriz_confusion$table["CON BCIAO", "CON BCIAO"]
    VN <- matriz_confusion$table["SIN BCIAO", "SIN BCIAO"]
    FP <- matriz_confusion$table["SIN BCIAO", "CON BCIAO"]
    FN <- matriz_confusion$table["CON BCIAO", "SIN BCIAO"]
    return((VP + VN) / (VP + VN + FP + FN))  # Tasa de Acierto
  }),
  F1_Score = sapply(thresholds, function(t) {
    precision_value <- confusionMatrix(factor(ifelse(pred_probs > t, "CON BCIAO", "SIN BCIAO"), 
                                              levels = c("CON BCIAO", "SIN BCIAO")),
                                       factor(testeo$BCIAO, levels = c("CON BCIAO", "SIN BCIAO")))$byClass["Pos Pred Value"]
    sensitivity_value <- confusionMatrix(factor(ifelse(pred_probs > t, "CON BCIAO", "SIN BCIAO"), 
                                                levels = c("CON BCIAO", "SIN BCIAO")),
                                         factor(testeo$BCIAO, levels = c("CON BCIAO", "SIN BCIAO")))$byClass["Sensitivity"]
    
    # Manejo de NA
    if (is.na(precision_value) || is.na(sensitivity_value) || 
        (precision_value + sensitivity_value) == 0) {
      return(0)  # Retorna 0 si hay NA o la suma es 0
    } else {
      return(2 * (precision_value * sensitivity_value) / (precision_value + sensitivity_value))  # F1 Score
    }
  })
)

# Graficar sensibilidad y especificidad a diferentes umbrales
ggplot(metrics, aes(x = Threshold)) +
  geom_line(aes(y = Sensitivity, color = "Sensibilidad"), size = 0.5) +
  geom_line(aes(y = Specificity, color = "Especificidad"), size = 0.5) +
  
  # Agregar líneas verdes con dobleces en x = 0.5645416 y cambios en y = 0.8618 y y = 0.8211
  geom_segment(aes(x = 0.5645416, xend = 0.5645416, y = 0, yend = 0.8618), color = "green", linetype = "dotted") +  # Línea vertical hasta y = 0.8618
  geom_segment(aes(x = 0, xend = 0.5645416, y = 0.8618, yend = 0.8618), color = "green", linetype = "dotted") +     # Línea horizontal hacia la izquierda en y = 0.8618
  geom_segment(aes(x = 0.5645416, xend = 0.5645416, y = 0.8618, yend = 0.8211), color = "green", linetype = "dotted") +  # Línea vertical desde y = 0.8618 hasta y = 0.8211
  geom_segment(aes(x = 0, xend = 0.5645416, y = 0.8211, yend = 0.8211), color = "green", linetype = "dotted") +    # Línea horizontal hacia la izquierda en y = 0.8211
  
  # Anotaciones en el eje Y
  annotate("text", x = 0, y = 0.8618, label = "0.8618", hjust = 0.4, color = "black", size = 3) +
  annotate("text", x = 0, y = 0.8211, label = "0.8211", hjust = 0.4, color = "black", size = 3) +
  
  labs(title = "Comportamiento de Sensibilidad y Especificidad en función del Umbral",
       x = "Umbral",
       y = "Valor") +
  scale_x_continuous(limits = c(0, 1)) +  # Establecer límites del eje x
  scale_y_continuous(limits = c(0, 1)) +  # Establecer límites del eje y
  theme_minimal() +
  scale_color_manual(name = "Métrica", 
                     values = c("Sensibilidad" = "blue", 
                                "Especificidad" = "red"))


ggplot(metrics, aes(x = Threshold)) +
  geom_line(aes(y = Sensitivity, color = "Sensibilidad"), size = 0.5) +
  geom_line(aes(y = Specificity, color = "Especificidad"), size = 0.5) +
  geom_line(aes(y = Tasa_Acierto, color = "Tasa de Acierto"), size = 0.5) +
  geom_line(aes(y = Precision, color = "Precisión"), size = 0.5) +
  geom_line(aes(y = F1_Score, color = "F1 Score"), size = 0.5) +  # Agregar F1 Score
  
  # Agregar línea desde x = 0.5645416 hasta el valor correspondiente de y = 0.8618
  geom_segment(aes(x = 0.5645416, xend = 0.5645416, y = 0, yend = 0.8618), color = "green", linetype = "dashed", size=0.3) +
  
  labs(title = "Metricas de rendimiento en función del Umbral",
       x = "Umbral",
       y = "Valor") +
  scale_x_continuous(limits = c(0, 1)) +  # Establecer límites del eje x
  scale_y_continuous(limits = c(0, 1)) +  # Establecer límites del eje y
  theme_minimal() +
  scale_color_manual(name = "Métrica", 
                     values = c("Sensibilidad" = "blue", 
                                "Especificidad" = "red", 
                                "Tasa de Acierto" = "green", 
                                "Precisión" = "purple", 
                                "F1 Score" = "orange"))  # Color para F1 Score

```

## SECUENCIACION DE UMBRALES

```{r echo=FALSE, include=FALSE}

#tabla de metricas en secuencia de umbrales 

# predicciones en el conjunto de prueba
# red_cv es el modelo entrenado
pred_cv <- predict(red_cv, newdata = testeo, type = "prob") # Obtiene las probabilidades

# Crea el dataframe de predicciones
predicciones <- data.frame(probabilidad = pred_cv[, "CON BCIAO"], # Columna de probabilidades para la clase positiva
                           real = testeo$BCIAO) # Columna de etiquetas reales

# Muestra las primeras filas del dataframe
head(predicciones)


# Inicializa un dataframe para almacenar los resultados
resultados <- data.frame(umbral = numeric(),
                         sensibilidad = numeric(),
                         especificidad = numeric(),
                         FP = numeric(),
                         FN = numeric(),
                         tasa_acierto = numeric(),
                         tasa_error = numeric(),
                         precision = numeric(),
                         F1_score = numeric())


# Recorre los umbrales del 0.1 al 0.75
for (umbral in seq(0.1, 0.75, by = 0.0001)) {
  
  # Genera predicciones basadas en el umbral
  predicciones_clasificadas <- ifelse(predicciones$probabilidad >= umbral, "CON BCIAO", "SIN BCIAO")
  
  # Crea la matriz de confusión
  matriz_confusion <- table(predicciones_clasificadas, predicciones$real)
  
  # Extrae los valores de la matriz de confusión
  VP <- matriz_confusion["CON BCIAO", "CON BCIAO"]
  FN <- matriz_confusion["CON BCIAO", "SIN BCIAO"]
  VN <- matriz_confusion["SIN BCIAO", "SIN BCIAO"]
  FP <- matriz_confusion["SIN BCIAO", "CON BCIAO"]
  F1_score <- ifelse(precision + sensibilidad == 0, 0, 2 * (precision * sensibilidad) / (precision + sensibilidad))
  
  # Agrega los resultados al dataframe
  resultados <- rbind(resultados, data.frame(umbral = umbral,
                                             sensibilidad = sensibilidad,
                                             especificidad = especificidad,
                                             FP = FP,
                                             FN = FN,
                                             tasa_acierto = tasa_acierto,
                                             tasa_error = tasa_error,
                                             precision = precision,
                                             F1_score = F1_score))
}

head (resultados)
# Filtrar para ver umbrales en el rango específico que me intersa
rango_resultados<-resultados[resultados$umbral >= 0.50 & resultados$umbral <= 0.55, ]
#options(max.print = 8000)  # O un número mayor según sea necesario
print(rango_resultados)
```

## PREDICCION DE CASOS

```{r echo=FALSE}

## PREDICCION DE CASOS ####
# nuevo caso 1 con umbral 0.5432122
# Definir el nuevo caso
caso1 <- data.frame(SEX= "M", FEY = 40, EDAD = 70, CIRUGIA= "COMBINADO", VALVULA= "BIOLOGICO", POSICION="AORTICO", HIPOT= "LEVE")

# Obtener las probabilidades de la clase positiva para el nuevo caso
probabilidades_caso1 <- predict(red_cv, newdata = caso1, type = "prob") #[, 1]  # Probabilidad de "CON BCIAO"

# Realizar la predicción de la clase basada en el umbral óptimo
prediccion_caso1 <- ifelse(probabilidades_caso1 > threshold, "CON BCIAO", "SIN BCIAO")
# Convertir a vector y hacer la predicción
prediccion_caso1 <- ifelse(as.numeric(probabilidades_caso1[1, "CON BCIAO"]) > threshold, "CON BCIAO", "SIN BCIAO")

# Imprimir las probabilidades y la predicción del caso
print(prediccion_caso1)
print(probabilidades_caso1)
```

# SVM

## MODELO PREDICTIVO  

```{r echo=FALSE, include=FALSE}
# Crear copia y ajustar niveles de `BCIAO` para nombres válidos
datos2 <- datos1
levels(datos2$BCIAO) <- make.names(levels(datos2$BCIAO))

# Particionamiento 70/30 en conjunto de entrenamiento y prueba
set.seed(27848992)
particion <- createDataPartition(y = datos2$BCIAO, p = 0.7, list = FALSE)
entreno_svm <- datos2[particion, ]
testeo_svm <- datos2[-particion, ]
```

## ENTRENAMIENTO DEL MODELO

```{r echo=FALSE, warning= FALSE}
# Crear dataframes finales de entrenamiento y prueba con 'BCIAO' como la variable respuesta
# y sin escalado
train_data <- data.frame(
  SEX = entreno_svm$SEX, 
  VALVULA = entreno_svm$VALVULA, 
  POSICION = entreno_svm$POSICION, 
  CIRUGIA = entreno_svm$CIRUGIA, 
  HIPOT = entreno_svm$HIPOT,
  EDAD = entreno_svm$EDAD,
  FEY = entreno_svm$FEY,
  BCIAO = entreno_svm$BCIAO
)

test_data <- data.frame(
  SEX = testeo_svm$SEX, 
  VALVULA = testeo_svm$VALVULA, 
  POSICION = testeo_svm$POSICION, 
  CIRUGIA = testeo_svm$CIRUGIA, 
  HIPOT = testeo_svm$HIPOT,
  EDAD = testeo_svm$EDAD,
  FEY = testeo_svm$FEY,
  BCIAO = testeo_svm$BCIAO
)

# Definir los rangos de hiperparámetros para `cost` y `sigma`
cost_values <- c(0.1, 1, 10, 100)
sigma_values <- c(0.01, 0.1, 1)
param_grid <- expand.grid(C = cost_values, sigma = sigma_values)

# Configurar el control de entrenamiento con validación cruzada
control <- trainControl(method = "cv", number = 5, classProbs = TRUE)

# Ajustar el modelo SVM con validación cruzada
set.seed(27848992)
modelo_svm_cv <- train(
  BCIAO ~ SEX + FEY + EDAD + CIRUGIA + VALVULA + POSICION + HIPOT,
  data = train_data,
  method = "svmRadial",
  trControl = control,
  tuneGrid = param_grid
)
```

```{r echo=FALSE}
# Imprimir los mejores hiperparámetros y resultados
print(modelo_svm_cv)
```
```{r echo=FALSE, include=FALSE}

# Crear un dataframe con los resultados del modelo
results_df <- modelo_svm_cv$results[, c("C", "sigma", "Accuracy")]

# Crear un gráfico 3D de los resultados
open3d()
plot3d(results_df$C, results_df$sigma, results_df$Accuracy,
       xlab = "Cost", ylab = "Sigma", zlab = "Accuracy",
       main = "Relación entre Hiperparámetros y Accuracy")

# Agregar puntos más grandes y de color rojo
spheres3d(results_df$C, results_df$sigma, results_df$Accuracy,
          radius = 0.6, color = "red")  # Aumenté el tamaño de los puntos a 0.3

```


```{r echo=FALSE}

varImpPlot <- varImp(modelo_svm_cv)
plot(varImpPlot, main = "Importancia de Variables")

```


## EVALUACION DEL MODELO 

```{r echo=FALSE}
# Hacer predicciones sobre el conjunto de prueba
predicciones_svm <- predict(modelo_svm_cv, test_data)

# Crear matriz de confusión y extraer tabla de confusión
matriz_confusion_svm <- confusionMatrix(predicciones_svm, test_data$BCIAO)
print(matriz_confusion_svm)

tabla_confusion_svm <- matriz_confusion_svm$table
print(tabla_confusion_svm)

# Calcular métricas
VP <- tabla_confusion_svm["CON.BCIAO", "CON.BCIAO"]
VN <- tabla_confusion_svm["SIN.BCIAO", "SIN.BCIAO"]
FP <- tabla_confusion_svm["CON.BCIAO", "SIN.BCIAO"]
FN <- tabla_confusion_svm["SIN.BCIAO", "CON.BCIAO"]

sensibilidad <- VP / (VP + FN)
especificidad <- VN / (VN + FP)
tasa_acierto <- (VP + VN) / (VP + VN + FP + FN)
tasa_error <- (FP + FN) / (VP + VN + FP + FN)
precision <- VP / (VP + FP)
F1_score <- 2 * (precision * sensibilidad) / (precision + sensibilidad)
print(F1_score)


```

```{r echo=FALSE}
# grafico 2

library(ROCR)
# Predecir probabilidades para el conjunto de prueba
predicciones_prob <- predict(modelo_svm_cv, test_data, type = "prob")

# Crear predicciones y etiquetas reales
pred <- prediction(predicciones_prob[,"CON.BCIAO"], test_data$BCIAO)

# Calcular precisión y recall
perf <- performance(pred, "prec", "rec")

# Graficar precisión-recall
plot(perf, main = "Curva de Precisión-Recall", col = "red")

```


## CURVA ROC Y AUC 

```{r echo=FALSE}


# Generar pobabilidades de predicción para la clase positiva
pred_probs <- predict(modelo_svm_cv, newdata = test_data, type = "prob")

# Crear curva ROC con las probabilidades de la clase positiva "CON.BCIAO"
roc_curve <- roc(test_data$BCIAO, pred_probs[, "CON.BCIAO"], levels = c("SIN.BCIAO", "CON.BCIAO"))


# Calcular AUC
auc_svm <- auc(roc_curve)
print(paste("AUC: ", auc_svm))

# Calcular intervalo de confianza para AUC
IC_auc_svm <- ci.auc(roc_curve, conf.level = 0.95)
print("Intervalo de confianza para el AUC:")
print(IC_auc_svm)


# visualizacion de la curva ROC
# Convertir el objeto ROC a un data frame para ggplot2
roc_data <- data.frame(
  Sensitivity = rev(roc_curve$sensitivities),
  Specificity = rev(1 - roc_curve$specificities)
)

# Graficar la curva ROC con ggplot2
ggplot(roc_data, aes(x = Specificity, y = Sensitivity)) +
  geom_line(color = "darkblue", size = 1.2) +                      # Curva ROC
  geom_ribbon(aes(ymin = 0, ymax = Sensitivity), fill = "skyblue", alpha = 0.4) +  # Sombreado de AUC uniforme
  labs(
    title = "Curva ROC",
    x = "1 - Especificidad (Tasa de Falsos Positivos)",
    y = "Sensibilidad (Tasa de Verdaderos Positivos)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 16),  # Título centrado y en negrita
    axis.title = element_text(size = 14),                              # Tamaño de títulos de ejes
    axis.text = element_text(size = 12)                                # Tamaño de etiquetas de ejes
  ) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "gray") +  # Línea de referencia diagonal
  scale_x_continuous(limits = c(0, 1)) +   # Limitar eje x entre 0 y 1
  scale_y_continuous(limits = c(0, 1))     # Limitar eje y entre 0 y 1


```



## PREDICCION DE UN CASO 

```{r echo=FALSE}
#### prediccion de caso con SVM ####

# Definir el nuevo caso y convertir a numérico y escalar
nuevo_caso <- data.frame(SEX= "M", FEY = 40, EDAD = 70, CIRUGIA= "COMBINADO", VALVULA= "BIOLOGICO", POSICION="AORTICO", HIPOT= "LEVE")

# Predecir la clase del nuevo caso y las probabilidades de cada clase
prediccion_clase <- predict(modelo_svm_cv, nuevo_caso)
prediccion_probabilidades <- predict(modelo_svm_cv, nuevo_caso, type = "prob")

# Imprimir los resultados
cat("Clase predicha:", prediccion_clase, "\n")
cat("Probabilidades de cada clase:\n")
print(prediccion_probabilidades)

```

# ____ INTRAQUIRÚRGICO (DIFF) ____

# RED NEURONAL 

## MODELO PREDICTIVO 

```{r echo=FALSE}
# Particionar los datos (70/30)
set.seed(27848992)
particion <- createDataPartition(y = datos$DIFF, p = 0.7, list = FALSE)
entreno <- datos[particion, ]
testeo <- datos[-particion, ]

# Verificar si hay valores NA en los datos de entrenamiento
summary(entreno)
summary(testeo)

# Corroboro cantidad de casos en la partición 
dim(entreno)
dim(testeo)

# Calcular el total de observaciones de DIFF en los datos completos
total_datos <- nrow(datos)

# Calcular el número de observaciones en los conjuntos de entrenamiento y prueba
num_entreno <- nrow(entreno)
num_testeo <- nrow(testeo)

# Calcular el porcentaje de observaciones en los conjuntos de entrenamiento y prueba
porc_entreno <- (num_entreno / total_datos) * 100
porc_testeo <- (num_testeo / total_datos) * 100
porc_entreno
porc_testeo

# Calcular estadísticas descriptivas para la variable DIFF en los tres conjuntos
# Medias
media_datos <- mean(datos$DIFF)
media_entreno <- mean(entreno$DIFF)
media_testeo <- mean(testeo$DIFF)

# Medianas
mediana_datos <- median(datos$DIFF)
mediana_entreno <- median(entreno$DIFF)
mediana_testeo <- median(testeo$DIFF)

# Rangos (mínimo y máximo)
rango_datos <- range(datos$DIFF)
rango_entreno <- range(entreno$DIFF)
rango_testeo <- range(testeo$DIFF)

# Crear una tabla con los resultados
resultados <- data.frame(
  Conjunto = c("Datos", "Entrenamiento", "Testeo"),
  Media = c(media_datos, media_entreno, media_testeo),
  Mediana = c(mediana_datos, mediana_entreno, mediana_testeo),
  Rango = c(paste(rango_datos[1], "-", rango_datos[2]),
            paste(rango_entreno[1], "-", rango_entreno[2]),
            paste(rango_testeo[1], "-", rango_testeo[2]))
)

# Mostrar la tabla con kable
kable(resultados, caption = "Estadísticos de DIFF en Datos, Entrenamiento y Testeo")
```


## ENTRENAMIENTO/EVALUACION DEL MODELO 

```{r echo=FALSE}

# Definir los rangos de hiperparámetros para `size` y `decay`
size_values <- c(1, 3, 5)
decay_values <- c(0, 0.01, 0.1)

# Crear una cuadrícula de combinaciones de hiperparámetros
param_grid <- expand.grid(size = size_values, decay = decay_values)

# Configurar el control de entrenamiento con validación cruzada
control <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Variables para almacenar los mejores resultados
mejor_rmse <- Inf
mejor_mae <- Inf
mejor_r2 <- -Inf  # Inicializar mejor R^2
mejor_modelo <- NULL
mejores_hiperparametros <- NULL

# Bucle para ajustar el modelo con cada combinación de hiperparámetros
for (i in 1:nrow(param_grid)) {
  # Obtener los valores actuales de size y decay
  size_actual <- param_grid$size[i]
  decay_actual <- param_grid$decay[i]
  
  # Entrenar el modelo de red neuronal con los hiperparámetros actuales
  modelo_nn <- train(DIFF ~ SEX + EDAD + CIRUGIA + VALVULA + POSICION + HIPOT, 
                     data = entreno,  # Usamos entreno sin escalar
                     method = "nnet", 
                     linout = TRUE, 
                     trace = FALSE,
                     preProcess = c("center", "scale"),  # Escalado automático
                     trControl = control,
                     maxit = 300,  # Limitar el número de iteraciones
                     tuneGrid = data.frame(size = size_actual, decay = decay_actual))
  
  # Hacer predicciones sobre el conjunto de prueba
  predicciones_nn <- predict(modelo_nn, newdata = testeo)  # Usamos testeo sin escalar
  
  # Calcular RMSE y MAE
  rmse_nn <- RMSE(predicciones_nn, testeo$DIFF)
  mae_nn <- MAE(predicciones_nn, testeo$DIFF)
  
  # Calcular R^2
  r2_nn <- cor(predicciones_nn, testeo$DIFF)^2  # Correlación al cuadrado
  
  # Guardar el modelo si tiene un RMSE mejor que el anterior mejor
  if (rmse_nn < mejor_rmse) {
    mejor_rmse <- rmse_nn
    mejor_mae <- mae_nn
    mejor_r2 <- r2_nn  # Actualizar el mejor R^2
    mejor_modelo <- modelo_nn
    mejores_hiperparametros <- list(size = size_actual, decay = decay_actual)
  }
}

# Imprimir los mejores hiperparámetros y métricas de desempeño
cat("Mejores hiperparámetros y métricas:\n")
cat("Size:", mejores_hiperparametros$size, "\n")
cat("Decay:", mejores_hiperparametros$decay, "\n")
cat("Mejor RMSE:", mejor_rmse, "\n")
cat("Mejor MAE:", mejor_mae, "\n")
cat("Mejor R^2:", mejor_r2, "\n")
```

```{r echo=FALSE}
# Crear un gráfico de comparación de predicciones
comparacion <- data.frame(real = testeo$DIFF, prediccion = predict(mejor_modelo, newdata = testeo))


ggplot(comparacion, aes(x = real, y = prediccion)) +
  geom_point(alpha = 0.6, color = "blue", size = 2) +  # Cambiar color y tamaño de puntos
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +  # Línea de referencia
  labs(title = "Predicciones vs Valores Reales (Conjunto de Prueba)",
       x = "Valores Reales (DIFF)",
       y = "Predicciones (DIFF)") +
  xlim(min(comparacion$real, comparacion$prediccion), max(comparacion$real, comparacion$prediccion)) +  # Limitar ejes
  ylim(min(comparacion$real, comparacion$prediccion), max(comparacion$real, comparacion$prediccion)) +
  theme_minimal(base_size = 15) +  # Aumentar el tamaño de base del tema
  theme(plot.title = element_text(hjust = 0.5))  # Centrar título
```

```{r echo=FALSE}
# Calcular residuos
residuos <- predicciones_nn- testeo$DIFF

# Gráfico de residuos
ggplot(data = data.frame(Residuo = residuos), aes(x = Residuo)) +
  geom_histogram(bins = 30, fill = "blue", alpha = 0.7) +
  labs(title = "Distribución de Residuos",
       x = "Residuo",
       y = "Frecuencia") +
  theme_minimal()
```

```{r echo=FALSE}
varImpPlot <- varImp( modelo_nn)
plot(varImpPlot, main = "Importancia de Variables")
```

## PREDICCION DE UN CASO 

```{r echo=FALSE}

# Definir el nuevo caso
nuevo_caso <- data.frame(SEX= "M", FEY = 40, EDAD = 70, CIRUGIA= "COMBINADO", VALVULA= "BIOLOGICO", POSICION="AORTICO", HIPOT= "LEVE")

# Convertir las variables categóricas en factores con los niveles correspondientes
nuevo_caso$SEX <- factor(nuevo_caso$SEX, levels = levels(entreno$SEX))
nuevo_caso$CIRUGIA <- factor(nuevo_caso$CIRUGIA, levels = levels(entreno$CIRUGIA))

# Añadir "NC" como nivel en VALVULA solo si no está ya presente
if (!"NC" %in% levels(entreno$VALVULA)) {
  nuevo_caso$VALVULA <- factor(nuevo_caso$VALVULA, levels = c(levels(entreno$VALVULA), "NC"))
} else {
  nuevo_caso$VALVULA <- factor(nuevo_caso$VALVULA, levels = levels(entreno$VALVULA))
}

# Añadir "NC" como nivel en POSICION solo si no está ya presente
if (!"NC" %in% levels(entreno$POSICION)) {
  nuevo_caso$POSICION <- factor(nuevo_caso$POSICION, levels = c(levels(entreno$POSICION), "NC"))
} else {
  nuevo_caso$POSICION <- factor(nuevo_caso$POSICION, levels = levels(entreno$POSICION))
}

# Convertir HIPOT a factor como en el conjunto de entrenamiento
nuevo_caso$HIPOT <- factor(nuevo_caso$HIPOT, levels = levels(entreno$HIPOT))

# Verificar que los niveles coincidan con los del conjunto de entrenamiento
str(nuevo_caso)

# Realizar la predicción con el mejor modelo encontrado
prediccion_nuevo_caso <- predict(mejor_modelo, newdata = nuevo_caso)

# Mostrar la predicción
cat("Predicción para el nuevo caso (DIFF):", prediccion_nuevo_caso, "\n")
```



# SVM

## MODELO PREDICTIVO 

```{r echo=FALSE}
# Particionamiento 70/30 en conjunto de entrenamiento y testeo
set.seed(27848992)
particion <- createDataPartition(y = datos$DIFF, p = 0.7, list = FALSE) 
entreno <- datos[particion, ]
testeo <- datos[-particion, ]

# Convertir todas las variables categóricas en factores y luego en numéricas para entreno y testeo
convertir_a_numerico <- function(df) {
  cols_categoricas <- c("SEX", "VALVULA", "POSICION", "CIRUGIA", "HIPOT")
  df[cols_categoricas] <- lapply(df[cols_categoricas], function(x) as.numeric(as.factor(x)))
  return(df)
}

# Aplicar la función a los conjuntos de datos
entreno_intra_svm <- convertir_a_numerico(entreno)
testeo_intra_svm<- convertir_a_numerico(testeo)
```

## ENTRENAMIENTO DEL MODELO 

```{r echo=FALSE}
# Definir los rangos de hiperparámetros para `cost` y `gamma`
cost_values <- c(0.1, 1, 10, 100)
sigma_values <- c(0.01, 0.1, 1)

# Crear una cuadrícula de combinaciones de hiperparámetros con los nombres correctos
param_grid <- expand.grid(C = cost_values, sigma = sigma_values)

# Configurar el control de entrenamiento con validación cruzada
control <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Ajustar el modelo SVM con validación cruzada y escalado automático
set.seed(123)  # Para reproducibilidad
modelo_svm_cv <- train(DIFF ~ SEX + EDAD + VALVULA + POSICION + FEY + CIRUGIA + HIPOT, 
                       data = entreno_intra_svm, 
                       method = "svmRadial",
                       trControl = control,
                       preProcess = c("center", "scale"),  # Escalado automático
                       tuneGrid = param_grid  # Para ajustar el modelo con los parámetros de SVM
)

# Imprimir los mejores hiperparámetros y resultados
print(modelo_svm_cv)
```
```{r echo=FALSE}
# grafico 
# Crear un dataframe con los resultados del modelo
results_df <- modelo_svm_cv$results[, c("C", "sigma", "RMSE")]

# Crear un gráfico 3D de los resultados
open3d()
plot3d(results_df$C, results_df$sigma, results_df$RMSE,
       xlab = "Cost", ylab = "Sigma", zlab = "RMSE",
       main = "Relación entre Hiperparámetros y RMSE")

# Agregar puntos más grandes y de color rojo
spheres3d(results_df$C, results_df$sigma, results_df$RMSE,
          radius = 0.6, color = "red")  # Aumenté el tamaño de los puntos a 0.3
```


## EVALUACION DEL MODELO 

```{r echo=FALSE}
# Hacer predicciones sobre el conjunto de prueba
predicciones_svm <- predict(modelo_svm_cv, testeo_intra_svm)

# Valores observados
observados <- testeo_intra_svm$DIFF

# Cálculo del R^2 manualmente
ss_res <- sum((observados - predicciones_svm)^2)
ss_tot <- sum((observados - mean(observados))^2)
r_squared <- 1 - (ss_res / ss_tot)

# Calcular RMSE y MAE
rmse_svm <- sqrt(mean((predicciones_svm - observados)^2))
mae_svm <- mean(abs(predicciones_svm - observados))

# Imprimir todas las métricas juntas
cat("R^2:", round(r_squared, 4), "\n")
cat("RMSE:", round(rmse_svm, 4), "\n")
cat("MAE:", round(mae_svm, 4), "\n")

```

```{r echo=FALSE}
# Crear un dataframe para el gráfico
resultados <- data.frame(Real = testeo_intra_svm$DIFF, Prediccion = predicciones_svm)

# Gráfico
ggplot(resultados, aes(x = Real, y = Prediccion)) +
  geom_point(color = "blue", alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Predicciones vs. Valores Reales",
       x = "Valores Reales",
       y = "Predicciones") +
  theme_minimal()
```

```{r echo=FALSE}
# Calcular residuos
residuos <- predicciones_svm - testeo_intra_svm$DIFF

# Gráfico de residuos
ggplot(data = data.frame(Residuo = residuos), aes(x = Residuo)) +
  geom_histogram(bins = 30, fill = "blue", alpha = 0.7) +
  labs(title = "Distribución de Residuos",
       x = "Residuo",
       y = "Frecuencia") +
  theme_minimal()
```

```{r echo=FALSE}

varImpPlot <- varImp(modelo_svm_cv)
plot(varImpPlot, main = "Importancia de Variables")

```


## PREDICCION DE UN CASO 

```{r echo=FALSE}
# Definir la función para convertir variables categóricas a numéricas
convertir_a_numerico <- function(df) {
  cols_categoricas <- c("SEX", "VALVULA", "POSICION", "CIRUGIA", "HIPOT")
  niveles_sex <- c("F", "M")
  niveles_valvula <- c("BIOLOGICO","MECANICO","NC")
  niveles_posicion <- c("AORTICO","AORTICO+MITRAL","MITRAL","NC")
  niveles_cirugia <- c("BENTALL","BENTALL+CRM","CIA","CIV","COMBINADO","CRM","CRVAO","CRVAO+CRVM","CRVM","RAA" )
  niveles_hipot <- c("LEVE","MODERADA")
  
  df$SEX <- factor(df$SEX, levels = niveles_sex)
  df$VALVULA <- factor(df$VALVULA, levels = niveles_valvula)
  df$POSICION <- factor(df$POSICION, levels = niveles_posicion)
  df$CIRUGIA <- factor(df$CIRUGIA, levels = niveles_cirugia)
  df$HIPOT <- factor(df$HIPOT, levels = niveles_hipot)
  
  df[cols_categoricas] <- lapply(df[cols_categoricas], function(x) as.numeric(x))
  return(df)
}

# definir el nuevo caso 
nuevo_caso <- data.frame(SEX= "M", FEY = 40, EDAD = 70, CIRUGIA= "COMBINADO", VALVULA= "BIOLOGICO", POSICION="AORTICO", HIPOT= "LEVE")

# Convertir las variables categóricas a numéricas en el nuevo caso
nuevo_caso <- convertir_a_numerico(nuevo_caso)

# Realizar la predicción utilizando el modelo SVM entrenado
prediccion_nuevo_caso <- predict(modelo_svm_cv, nuevo_caso)

# Imprimir la predicción
print(prediccion_nuevo_caso)
```

# BASE DE DATOS SIN OUTLIERS DE DIFF

```{r echo=FALSE}

# Filtrar los outliers que corresponden solo a la variable DIFF 
#     (TOMADO DEL APARTADO IDENTIFICACION DE OUTLIERS)

outliers_diff <- df_outliers[df_outliers$Variable == "DIFF", ]

# Mostrar el número de outliers en DIFF y los primeros registros
cat("Número de outliers en la variable DIFF:", nrow(outliers_diff), "\n")

# Eliminar los registros de outliers_diff en la base de datos datos
datos_sin_outliers <- datos[!(datos$DIFF %in% outliers_diff$DIFF), ]

# Verificar el número de registros después de eliminar los outliers
cat("Número de registros después de eliminar los outliers:", nrow(datos_sin_outliers), "\n")
```

# RED NEURONAL SIN OUTLIERS

```{r echo=FALSE}

# Particionar los datos (70/30)
set.seed(27848992)
particion <- createDataPartition(y = datos_sin_outliers$DIFF, p = 0.7, list = FALSE)
entreno <- datos_sin_outliers[particion, ]
testeo <- datos_sin_outliers[-particion, ]

# Verificar si hay valores NA en los datos de entrenamiento
summary(entreno)
summary(testeo)

# Corroboro cantidad de casos en la partición 
dim(entreno)
dim(testeo)

# Calcular el total de observaciones de DIFF en los datos completos
total_datos <- nrow(datos_sin_outliers)

# Calcular el número de observaciones en los conjuntos de entrenamiento y prueba
num_entreno <- nrow(entreno)
num_testeo <- nrow(testeo)

# Calcular el porcentaje de observaciones en los conjuntos de entrenamiento y prueba
porc_entreno <- (num_entreno / total_datos) * 100
porc_testeo <- (num_testeo / total_datos) * 100
porc_entreno
porc_testeo

# Calcular estadísticas descriptivas para la variable DIFF en los tres conjuntos
# Medias
media_datos <- mean(datos_sin_outliers$DIFF)
media_entreno <- mean(datos_sin_outliers$DIFF)
media_testeo <- mean(datos_sin_outliers$DIFF)

# Medianas
mediana_datos <- median(datos_sin_outliers$DIFF)
mediana_entreno <- median(datos_sin_outliers$DIFF)
mediana_testeo <- median(datos_sin_outliers$DIFF)

# Rangos (mínimo y máximo)
rango_datos <- range(datos_sin_outliers$DIFF)
rango_entreno <- range(datos_sin_outliers$DIFF)
rango_testeo <- range(datos_sin_outliers$DIFF)

# Crear una tabla con los resultados
resultados <- data.frame(
  Conjunto = c("Datos", "Entrenamiento", "Testeo"),
  Media = c(media_datos, media_entreno, media_testeo),
  Mediana = c(mediana_datos, mediana_entreno, mediana_testeo),
  Rango = c(paste(rango_datos[1], "-", rango_datos[2]),
            paste(rango_entreno[1], "-", rango_entreno[2]),
            paste(rango_testeo[1], "-", rango_testeo[2]))
)

# Mostrar la tabla con kable
kable(resultados, caption = "Estadísticos de DIFF en Datos, Entrenamiento y Testeo")

# Definir los rangos de hiperparámetros para `size` y `decay`
size_values <- c(1, 3, 5)
decay_values <- c(0, 0.01, 0.1)

# Crear una cuadrícula de combinaciones de hiperparámetros
param_grid <- expand.grid(size = size_values, decay = decay_values)

# Configurar el control de entrenamiento con validación cruzada
control <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Variables para almacenar los mejores resultados
mejor_rmse <- Inf
mejor_mae <- Inf
mejor_r2 <- -Inf  # Inicializar mejor R^2
mejor_modelo <- NULL
mejores_hiperparametros <- NULL

# Bucle para ajustar el modelo con cada combinación de hiperparámetros
for (i in 1:nrow(param_grid)) {
  # Obtener los valores actuales de size y decay
  size_actual <- param_grid$size[i]
  decay_actual <- param_grid$decay[i]
  
  # Entrenar el modelo de red neuronal con los hiperparámetros actuales
  modelo_nn <- train(DIFF ~ SEX + EDAD + CIRUGIA + VALVULA + POSICION + HIPOT, 
                     data = entreno,  # Usamos entreno sin escalar
                     method = "nnet", 
                     linout = TRUE, 
                     trace = FALSE,
                     preProcess = c("center", "scale"),  # Escalado automático
                     trControl = control,
                     maxit = 300,  # Limitar el número de iteraciones
                     tuneGrid = data.frame(size = size_actual, decay = decay_actual))
  
  # Hacer predicciones sobre el conjunto de prueba
  predicciones_nn <- predict(modelo_nn, newdata = testeo)  # Usamos testeo sin escalar
  
  # Calcular RMSE y MAE
  rmse_nn <- RMSE(predicciones_nn, testeo$DIFF)
  mae_nn <- MAE(predicciones_nn, testeo$DIFF)
  
  # Calcular R^2
  r2_nn <- cor(predicciones_nn, testeo$DIFF)^2  # Correlación al cuadrado
  
  # Guardar el modelo si tiene un RMSE mejor que el anterior mejor
  if (rmse_nn < mejor_rmse) {
    mejor_rmse <- rmse_nn
    mejor_mae <- mae_nn
    mejor_r2 <- r2_nn  # Actualizar el mejor R^2
    mejor_modelo <- modelo_nn
    mejores_hiperparametros <- list(size = size_actual, decay = decay_actual)
  }
}

# Imprimir los mejores hiperparámetros y métricas de desempeño
cat("Mejores hiperparámetros:\n")
cat("Size:", mejores_hiperparametros$size, "\n")
cat("Decay:", mejores_hiperparametros$decay, "\n")
cat("Mejor RMSE:", mejor_rmse, "\n")
cat("Mejor MAE:", mejor_mae, "\n")
cat("Mejor R^2:", mejor_r2, "\n")

```


```{r echo=FALSE}
varImpPlot <- varImp(modelo_nn)
plot(varImpPlot, main = "Importancia de Variables")
```


```{r echo=FALSE}
# Crear un gráfico de comparación de predicciones
comparacion <- data.frame(real = testeo$DIFF, prediccion = predict(mejor_modelo, newdata = testeo))

ggplot(comparacion, aes(x = real, y = prediccion)) +
  geom_point(alpha = 0.6, color = "blue", size = 2) +  # Cambiar color y tamaño de puntos
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +  # Línea de referencia
  labs(title = "Predicciones vs Valores Reales (Conjunto de Prueba)",
       x = "Valores Reales (DIFF)",
       y = "Predicciones (DIFF)") +
  xlim(min(comparacion$real, comparacion$prediccion), max(comparacion$real, comparacion$prediccion)) +  # Limitar ejes
  ylim(min(comparacion$real, comparacion$prediccion), max(comparacion$real, comparacion$prediccion)) +
  theme_minimal(base_size = 15) +  # Aumentar el tamaño de base del tema
  theme(plot.title = element_text(hjust = 0.5))  # Centrar título
```

```{r echo=FALSE}
# Calcular residuos
residuos <- predicciones_nn- testeo$DIFF

# Gráfico de residuos
ggplot(data = data.frame(Residuo = residuos), aes(x = Residuo)) +
  geom_histogram(bins = 30, fill = "blue", alpha = 0.7) +
  labs(title = "Distribución de Residuos",
       x = "Residuo",
       y = "Frecuencia") +
  theme_minimal()
```


## PREDICCIÓN DE UN CASO

```{r echo=FALSE}
# Definir el nuevo caso
nuevo_caso <- data.frame(SEX= "M", FEY = 40, EDAD = 70, CIRUGIA= "COMBINADO", VALVULA= "BIOLOGICO", POSICION="AORTICO", HIPOT= "LEVE")

# Convertir las variables categóricas en factores con los niveles correspondientes
nuevo_caso$SEX <- factor(nuevo_caso$SEX, levels = levels(entreno$SEX))
nuevo_caso$CIRUGIA <- factor(nuevo_caso$CIRUGIA, levels = levels(entreno$CIRUGIA))

# Añadir "NC" como nivel en VALVULA solo si no está ya presente
if (!"NC" %in% levels(entreno$VALVULA)) {
  nuevo_caso$VALVULA <- factor(nuevo_caso$VALVULA, levels = c(levels(entreno$VALVULA), "NC"))
} else {
  nuevo_caso$VALVULA <- factor(nuevo_caso$VALVULA, levels = levels(entreno$VALVULA))
}

# Añadir "NC" como nivel en POSICION solo si no está ya presente
if (!"NC" %in% levels(entreno$POSICION)) {
  nuevo_caso$POSICION <- factor(nuevo_caso$POSICION, levels = c(levels(entreno$POSICION), "NC"))
} else {
  nuevo_caso$POSICION <- factor(nuevo_caso$POSICION, levels = levels(entreno$POSICION))
}

# Convertir HIPOT a factor como en el conjunto de entrenamiento
nuevo_caso$HIPOT <- factor(nuevo_caso$HIPOT, levels = levels(entreno$HIPOT))

# Verificar que los niveles coincidan con los del conjunto de entrenamiento
str(nuevo_caso)

# Realizar la predicción con el mejor modelo encontrado
prediccion_nuevo_caso <- predict(mejor_modelo, newdata = nuevo_caso)

# Mostrar la predicción
cat("Predicción para el nuevo caso (DIFF):", prediccion_nuevo_caso, "\n")
```

# SVM SIN OUTLIERS
```{r echo=FALSE}
# Particionamiento 70/30 en conjunto de entrenamiento y testeo
set.seed(27848992)
particion <- createDataPartition(y = datos_sin_outliers$DIFF, p = 0.7, list = FALSE) 
entreno <- datos_sin_outliers[particion, ]
testeo <- datos_sin_outliers[-particion, ]

# Convertir todas las variables categóricas en factores y luego en numéricas para entreno y testeo
convertir_a_numerico <- function(df) {
  cols_categoricas <- c("SEX", "VALVULA", "POSICION", "CIRUGIA", "HIPOT")
  df[cols_categoricas] <- lapply(df[cols_categoricas], function(x) as.numeric(as.factor(x)))
  return(df)
}

# Aplicar la función a los conjuntos de datos
entreno_intra_svm <- convertir_a_numerico(entreno)
testeo_intra_svm<- convertir_a_numerico(testeo)

# Definir los rangos de hiperparámetros para `cost` y `gamma`
cost_values <- c(0.1, 1, 10, 100)
sigma_values <- c(0.01, 0.1, 1)

# Crear una cuadrícula de combinaciones de hiperparámetros con los nombres correctos
param_grid <- expand.grid(C = cost_values, sigma = sigma_values)

# Configurar el control de entrenamiento con validación cruzada
control <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Ajustar el modelo SVM con validación cruzada y escalado automático
set.seed(27848992)  # Para reproducibilidad
modelo_svm_cv <- train(DIFF ~ SEX + EDAD + VALVULA + POSICION + FEY + CIRUGIA + HIPOT, 
                       data = entreno_intra_svm, 
                       method = "svmRadial",
                       trControl = control,
                       preProcess = c("center", "scale"),  # Escalado automático
                       tuneGrid = param_grid  # Para ajustar el modelo con los parámetros de SVM
)

# Imprimir los mejores hiperparámetros y resultados
print(modelo_svm_cv)


```

```{r echo=FALSE}

# grafico 
# Crear un dataframe con los resultados del modelo
results_df <- modelo_svm_cv$results[, c("C", "sigma", "RMSE")]

# Crear un gráfico 3D de los resultados
open3d()
plot3d(results_df$C, results_df$sigma, results_df$RMSE,
       xlab = "Cost", ylab = "Sigma", zlab = "RMSE",
       main = "Relación entre Hiperparámetros y RMSE")

# Agregar puntos más grandes y de color rojo
spheres3d(results_df$C, results_df$sigma, results_df$RMSE,
          radius = 0.6, color = "red")  # Aumenté el tamaño de los puntos a 0.3

```

```{r echo=FALSE}
# Hacer predicciones sobre el conjunto de prueba
predicciones_svm <- predict(modelo_svm_cv, testeo_intra_svm)

# Valores observados
observados <- testeo_intra_svm$DIFF

# Cálculo del R^2 manualmente
ss_res <- sum((observados - predicciones_svm)^2)
ss_tot <- sum((observados - mean(observados))^2)
r_squared <- 1 - (ss_res / ss_tot)

# Calcular RMSE y MAE
rmse_svm <- sqrt(mean((predicciones_svm - observados)^2))
mae_svm <- mean(abs(predicciones_svm - observados))

# Imprimir todas las métricas juntas
cat("R^2:", round(r_squared, 4), "\n")
cat("RMSE:", round(rmse_svm, 4), "\n")
cat("MAE:", round(mae_svm, 4), "\n")
```

```{r echo=FALSE}

# Crear un dataframe para el gráfico
resultados <- data.frame(Real = testeo_intra_svm$DIFF, Prediccion = predicciones_svm)

# Gráfico
ggplot(resultados, aes(x = Real, y = Prediccion)) +
  geom_point(color = "blue", alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Predicciones vs. Valores Reales",
       x = "Valores Reales",
       y = "Predicciones") +
  theme_minimal()

```

```{r echo=FALSE}

# Calcular residuos
residuos <- predicciones_svm - testeo_intra_svm$DIFF

# Gráfico de residuos
ggplot(data = data.frame(Residuo = residuos), aes(x = Residuo)) +
  geom_histogram(bins = 30, fill = "blue", alpha = 0.7) +
  labs(title = "Distribución de Residuos",
       x = "Residuo",
       y = "Frecuencia") +
  theme_minimal()

varImpPlot <- varImp(modelo_svm_cv)
plot(varImpPlot, main = "Importancia de Variables")
```

# PREDICCION DE UN CASO

```{r echo=FALSE}
# Definir la función para convertir variables categóricas a numéricas
convertir_a_numerico <- function(df) {
  cols_categoricas <- c("SEX", "VALVULA", "POSICION", "CIRUGIA", "HIPOT")
  niveles_sex <- c("F", "M")
  niveles_valvula <- c("BIOLOGICO","MECANICO","NC")
  niveles_posicion <- c("AORTICO","AORTICO+MITRAL","MITRAL","NC")
  niveles_cirugia <- c("BENTALL","BENTALL+CRM","CIA","CIV","COMBINADO","CRM","CRVAO","CRVAO+CRVM","CRVM","RAA" )
  niveles_hipot <- c("LEVE","MODERADA")
  
  df$SEX <- factor(df$SEX, levels = niveles_sex)
  df$VALVULA <- factor(df$VALVULA, levels = niveles_valvula)
  df$POSICION <- factor(df$POSICION, levels = niveles_posicion)
  df$CIRUGIA <- factor(df$CIRUGIA, levels = niveles_cirugia)
  df$HIPOT <- factor(df$HIPOT, levels = niveles_hipot)
  
  df[cols_categoricas] <- lapply(df[cols_categoricas], function(x) as.numeric(x))
  return(df)
}

# Definir el nuevo caso
nuevo_caso <- data.frame(SEX= "M", FEY = 40, EDAD = 70, CIRUGIA= "COMBINADO", VALVULA= "BIOLOGICO", POSICION="AORTICO", HIPOT= "LEVE")

# Convertir las variables categóricas a numéricas en el nuevo caso
nuevo_caso <- convertir_a_numerico(nuevo_caso)

# Realizar la predicción utilizando el modelo SVM entrenado
prediccion_nuevo_caso <- predict(modelo_svm_cv, nuevo_caso)

# Imprimir la predicción
print(prediccion_nuevo_caso)
```

